{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_readline(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.readlines()\n",
    "    return data\n",
    "def read_data(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "def write_data(file, data):\n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        f.write(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Niras\t Dataset/DataNirat/Niras.txt\n",
      "2 Lugsanawong\t Dataset/DataNitan/Lugsanawong.txt\n",
      "3 Phaapaimanee\t Dataset/DataNitan/Phaapaimanee.txt\n",
      "4 Cobuut\t Dataset/DataNitan/Cobuut.txt\n",
      "5 Singtaipop\t Dataset/DataNitan/Singtaipop.txt\n"
     ]
    }
   ],
   "source": [
    "NaratFile = 'Dataset/DataNirat/Niras.txt'\n",
    "NitanFiles = glob.glob('Dataset/DataNitan/*.txt')\n",
    "\n",
    "files = [NaratFile] + NitanFiles\n",
    "names = [file.split('/')[-1].split('.')[0] for file in files]\n",
    "for i in range(len(files)):\n",
    "    print(i+1, names[i]+'\\t', files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line of Niras \t\t 2652\n",
      "Line of Lugsanawong \t\t 4591\n",
      "Line of Phaapaimanee \t\t 48688\n",
      "Line of Cobuut \t\t 2606\n",
      "Line of Singtaipop \t\t 6740\n",
      "Total line: 65277\n",
      "Write file: Dataset/AllData.txt\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "count_line = 0\n",
    "for i in range(len(files)):\n",
    "    temp = read_data(files[i])\n",
    "    count_line += len(temp.split('\\n'))\n",
    "    print('Line of', names[i], '\\t\\t', len(temp.split('\\n')))\n",
    "    data.append(temp)\n",
    "print('Total line:', count_line)\n",
    "\n",
    "text = '\\n'.join(data)\n",
    "write_data('Dataset/AllData.txt', text)\n",
    "print('Write file: Dataset/AllData.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read AllData file And Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line: 65277\n",
      "Before: ['                                                โอ้สังเวชวาสนานิจจาเอ๋ย\\n', 'จะมีคู่มิได้อยู่ประคองเชย\\t            ต้องละเลยดวงใจไว้ไกลตา\\n', 'ถึงทุกข์ใครในโลกที่โศกเศร้า\\tไม่เหมือนเราภุมรินถวิลหา\\n']\n",
      "Length data : 65277\n",
      "After: ['จะมีคู่มิได้อยู่ประคองเชย ต้องละเลยดวงใจไว้ไกลตา', 'ถึงทุกข์ใครในโลกที่โศกเศร้า ไม่เหมือนเราภุมรินถวิลหา', 'จะพลัดพรากจากกันไม่ทันลา ใช้แต่ตาต่างถ้อยสุนทรวอน']\n",
      "Length data2 : 65258\n"
     ]
    }
   ],
   "source": [
    "file = 'Dataset/AllData.txt'\n",
    "data = read_data_readline(file)\n",
    "\n",
    "print('Line:', len(data))\n",
    "\n",
    "# Split each line by whitespace and remove words with length less than 2\n",
    "data2 = [[word for word in line.split() if len(word) >= 2] for line in data]\n",
    "# Remove lines with a length of 1\n",
    "data2 = [line for line in data2 if len(line) > 1]\n",
    "# Join word in line\n",
    "data2 = [' '.join(line) for line in data2]\n",
    "\n",
    "\n",
    "# show before and after data and data2  \n",
    "print('Before:', data[:3])\n",
    "print('Length data :', len(data))\n",
    "print('After:', data2[:3])\n",
    "print('Length data2 :', len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จะมีคู่มิได้อยู่ประคองเชย ต้องละเลยดวงใจไว้ไกลตา\n",
      "ถึงทุกข์ใครในโลกที่โศกเศร้า ไม่เหมือนเราภุมรินถวิลหา\n",
      "จะพลัดพรากจากกันไม่ทันลา ใช้แต่ตาต่างถ้อยสุนทรวอน\n",
      "โอ้จำใจไกลนุชสุดสวาท จึงนิราศเรื่องรักเป็นอักษร\n"
     ]
    }
   ],
   "source": [
    "text = '\\n'.join([line for line in np.array(data2[:4]).flatten()])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ['๑', '๒', '๓', '๔', '๕', '๗', '[', ']', '๏', '๐', '๖', '๘', '๙']\n",
    "# Remove characters in c from text lines\n",
    "data2 = [''.join([char for char in line if char not in c]) for line in data2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  3471448\n",
      "Total Vocab:  74\n"
     ]
    }
   ],
   "source": [
    "text = '\\n'.join([line for line in np.array(data2).flatten()])\n",
    "\n",
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    " \n",
    "# summarize the loaded data\n",
    "n_chars = len(text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '-', '.', 'ก', 'ข', 'ฃ', 'ค', 'ฆ', 'ง', 'จ', 'ฉ', 'ช', 'ซ', 'ฌ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท', 'ธ', 'น', 'บ', 'ป', 'ผ', 'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ฤ', 'ล', 'ฦ', 'ว', 'ศ', 'ษ', 'ส', 'ห', 'ฬ', 'อ', 'ฮ', 'ฯ', 'ะ', 'ั', 'า', 'ำ', 'ิ', 'ี', 'ึ', 'ื', 'ุ', 'ู', 'ฺ', 'เ', 'แ', 'โ', 'ใ', 'ไ', 'ๅ', '็', '่', '้', '๊', '๋', '์', 'ํ']\n"
     ]
    }
   ],
   "source": [
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write file: Dataset/TextAfterNormalize.txt\n"
     ]
    }
   ],
   "source": [
    "# Create the file and write the normalized text\n",
    "text = '\\n'.join([line for line in np.array(data2)])\n",
    "file = 'Dataset/TextAfterNormalize.txt'\n",
    "write_data(file, text)\n",
    "print('Write file:', file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Load dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample : \n",
      " จะมีคู่มิได้อยู่ประคองเชย ต้องละเลยดวงใจไว้ไกลตา\n",
      "ถึงทุกข์ใครในโลกที่โศกเศร้า ไม่เหมือนเราภุมรินถวิลหา\n",
      "จะพลัดพรากจากกันไม่ทันลา ใช้แต่ตาต่างถ้อยสุนทรวอน\n",
      "โอ้จำใจไกลนุชสุดสวาท จึงนิราศเรื่องรักเป็นอักษร\n",
      "Length Line : 65258\n"
     ]
    }
   ],
   "source": [
    "file = 'Dataset/TextAfterNormalize.txt'\n",
    "data = read_data(file).split('\\n')\n",
    "data = [line for line in data if len(line) > 1]\n",
    "text = '\\n'.join([line for line in data[:4]])\n",
    "print(\"Sample : \\n\", text)\n",
    "print('Length Line :', len(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
